[audio]
sampling_rate = 16000
segment_length = 65536
channels = 2
normalize = True
dtype = float32

[dataset]
datapath = /path/to/your/cloud/audio/folder
test_dataset = test_audio
streaming = True
max_files = 
shuffle = True
hop_size = 32768
num_workers = 4
check_audio = True
check_dataset = True

[model]
net_type = UNetV0
in_channels = 2
channels = [8, 32, 64, 128, 256, 512, 512, 1024, 1024]
factors = [1, 4, 4, 4, 2, 2, 2, 2, 2]
items = [1, 2, 2, 2, 2, 2, 2, 4, 4]
attentions = [0, 0, 0, 0, 0, 1, 1, 1, 1]
attention_heads = 8
attention_features = 64
diffusion_type = VDiffusion
sampler_type = VSampler
loss_function = mse_loss

[training]
epochs = 200
learning_rate = 0.0001
batch_size = 16
optimizer = AdamW
device = cuda:0
save_every = 10
sample_every = 5
max_batches_per_epoch = 1000
gradient_clip = 1.0

[paths]
workspace = D:\kelse\03_Repositories\Kelsey_audio-diffusion-pytorch
checkpoint_dir = {timestamp}_{experiment}
training_audio_dir = training_audio

[monitoring]
generate_samples = True
num_samples_per_epoch = 5
sample_steps = 50
save_best_model = True
track_loss = True
progress_bar = True

[notes]
additional_notes = Production config for high-quality audio generation - segment_length=65536 samples (~4.1s at 16kHz) - hop_size=32768 (50% overlap) - batch_size=16 - max_batches_per_epoch=1000 - Model=[8,32,64,128,256,512,512,1024,1024] (~50M+ params) - Long training for high quality - Expected time: days to weeks - Recommended: RTX 3080+ with 12GB+ VRAM

[extra]
description = 20250113_audio-diffusion-kelsey-production-training
start_time = 
end_time = 
time_elapsed = 
best_loss = 
total_samples_generated = 
gpu_memory_used = 
notes_during_training = 

[resume]
resume_from_checkpoint = False
checkpoint_path = 
start_epoch = 0 