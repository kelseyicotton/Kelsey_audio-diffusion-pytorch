[audio]
sampling_rate = 16000
segment_length = 65536
channels = 2
normalize = True
dtype = float32

[dataset]
datapath = /mimer/NOBACKUP/groups/x_kelco_musai_2024/LJSpeech-1.1
test_dataset = test_audio
streaming = True
max_files = 
shuffle = True
hop_size = 32768
num_workers = 4
check_audio = True
check_dataset = True

[model]
net_type = UNetV0
in_channels = 2
channels = [8, 32, 64, 128, 256, 512, 512, 1024, 1024]
factors = [1, 4, 4, 4, 2, 2, 2, 2, 2]
items = [1, 2, 2, 2, 2, 2, 2, 4, 4]
attentions = [0, 0, 0, 0, 0, 1, 1, 1, 1]
attention_heads = 8
attention_features = 64
diffusion_type = VDiffusion
sampler_type = VSampler
loss_function = mse_loss

[training]
epochs = 2000
learning_rate = 0.0001
batch_size = 32
optimizer = AdamW
device = cuda:0
save_every = 50
sample_every = 50
max_batches_per_epoch = 300
gradient_clip = 1.0

[paths]
workspace = /mimer/NOBACKUP/groups/x_kelco_musai_2024
checkpoint_dir = {timestamp}_{experiment}
training_audio_dir = training_audio

[monitoring]
generate_amples = True
num_samples_per_epoch = 5
sample_steps = 100
save_best_model = True
track_loss = True
progress_bar = True

[notes]
additional_notes = A100 — segment_length=65536 (~4.1s@16kHz) — hop=32768 (50%) — mono (channels=1) — batch_size=32 (increase if VRAM allows) — max_batches_per_epoch=300 (≈600k steps @2000 epochs) — ~50M params — use AMP for throughput
[extra]
description = 20250926_audio-diffusion-kelsey-production-training_LJSpeech
start_time = 
end_time = 
time_elapsed = 
best_loss = 
total_samples_generated = 
gpu_memory_used = 
notes_during_training = 

[resume]resume_from_checkpoint = False
checkpoint_path = 
start_epoch = 0 